{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Segmentation Analysis\n",
    "\n",
    "## 1. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load and prepare data\n",
    "customers_df = pd.read_csv('Customers.csv')\n",
    "transactions_df = pd.read_csv('Transactions.csv')\n",
    "\n",
    "# Create customer features for clustering\n",
    "def create_clustering_features(customers_df, transactions_df):\n",
    "    # Calculate customer metrics\n",
    "    customer_metrics = transactions_df.groupby('CustomerID').agg({\n",
    "        'TotalValue': ['sum', 'mean', 'count'],\n",
    "        'Quantity': ['sum', 'mean']\n",
    "    })\n",
    "    \n",
    "    # Add customer profile information\n",
    "    customer_metrics = customer_metrics.join(pd.get_dummies(customers_df.set_index('CustomerID')['Region']))\n",
    "    \n",
    "    return customer_metrics\n",
    "\n",
    "clustering_features = create_clustering_features(customers_df, transactions_df)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(clustering_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Find optimal number of clusters\n",
    "db_scores = []\n",
    "K = range(2, 11)\n",
    "\n",
    "for k in K:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(scaled_features)\n",
    "    db_scores.append(davies_bouldin_score(scaled_features, kmeans.labels_))\n",
    "\n",
    "# Plot DB Index scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(K, db_scores, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Davies-Bouldin Index')\n",
    "plt.title('Optimal number of clusters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Perform final clustering\n",
    "optimal_k = K[np.argmin(db_scores)]\n",
    "final_kmeans = KMeans(n_clusters=optimal_k, random_state=42)\n",
    "cluster_labels = final_kmeans.fit_predict(scaled_features)\n",
    "\n",
    "# Add cluster labels to original data\n",
    "clustering_features['Cluster'] = cluster_labels\n",
    "\n",
    "# Analyze clusters\n",
    "print(\"Cluster Sizes:\")\n",
    "print(clustering_features['Cluster'].value_counts())\n",
    "\n",
    "print(\"\\nDavies-Bouldin Index:\", davies_bouldin_score(scaled_features, cluster_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 }
}